
========================================
Experiment conducted on: 2024-12-14 15:13:10.596422

Hyperparameters:
name: GlobalLocalKernel
trainable: True
verbose: True
is_fitted: False
ignored_attrs: ['train_set', 'val_set', 'test_set']
num_users: None
num_items: None
uid_map: None
iid_map: None
max_rating: 4.0
min_rating: 1.0
global_mean: None
_Recommender__user_ids: None
_Recommender__item_ids: None
n_hid: 10
n_dim: 2
n_layers: 2
lambda_s: 0.006
lambda_2: 0.001
gk_size: 3
dot_scale: 1
max_epoch_p: 30
max_epoch_f: 100
tol_p: 0.0001
tol_f: 1e-05
patience_p: 10
patience_f: 10
lr_p: 0.1
lr_f: 0.01
device: cpu
model: CompleteNet(
  (local_kernel_net): KernelNet(
    (layers): ModuleList(
      (0-1): 2 x KernelLayer(
        (activation): Sigmoid()
      )
      (2): KernelLayer(
        (activation): Identity()
      )
    )
    (dropout): Dropout(p=0.33, inplace=False)
  )
)
train_r_local: [[4.2188277 3.322004  3.6511939 ... 1.7437497 3.1620636 4.629881 ]
 [4.2188277 3.322004  3.6511939 ... 1.7437497 3.1620636 4.629881 ]
 [4.2188277 3.322004  3.6511939 ... 1.7437497 3.1620636 4.629881 ]
 ...
 [4.2188277 3.322004  3.6511939 ... 1.7437497 3.1620636 4.629881 ]
 [4.2188277 3.322004  3.6511939 ... 1.7437497 3.1620636 4.629881 ]
 [4.2188277 3.322004  3.6511939 ... 1.7437497 3.1620636 4.629881 ]]
_train_r: [[5. 0. 0. ... 0. 0. 0.]
 [0. 4. 0. ... 0. 0. 0.]
 [0. 0. 5. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 5. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
_train_mask: [[1. 0. 0. ... 0. 0. 0.]
 [0. 1. 0. ... 0. 0. 0.]
 [0. 0. 1. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 1. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]

Test Results:
Pre-Training Epoch 1/30, Train RMSE: 2.7996
Pre-Training Epoch 2/30, Train RMSE: 2.7996
Pre-Training Epoch 3/30, Train RMSE: 2.7995
Pre-Training Epoch 4/30, Train RMSE: 2.6134
Pre-Training Epoch 5/30, Train RMSE: 2.2041
Pre-Training Epoch 6/30, Train RMSE: 1.7501
Pre-Training Epoch 7/30, Train RMSE: 1.3298
Pre-Training Epoch 8/30, Train RMSE: 1.0646
Pre-Training Epoch 9/30, Train RMSE: 0.9996
Pre-Training Epoch 10/30, Train RMSE: 0.9842
Pre-Training Epoch 11/30, Train RMSE: 0.8989
Pre-Training Epoch 12/30, Train RMSE: 0.8207
Pre-Training Epoch 13/30, Train RMSE: 0.8701
Pre-Training Epoch 14/30, Train RMSE: 0.9979
Pre-Training Epoch 15/30, Train RMSE: 1.0676
Pre-Training Epoch 16/30, Train RMSE: 1.0539
Pre-Training Epoch 17/30, Train RMSE: 0.9845
Pre-Training Epoch 18/30, Train RMSE: 0.9100
Pre-Training Epoch 19/30, Train RMSE: 0.8543
Pre-Training Epoch 20/30, Train RMSE: 0.8262
Pre-Training Epoch 21/30, Train RMSE: 0.8108
Pre-Training Epoch 22/30, Train RMSE: 0.8003
Pre-Training Epoch 23/30, Train RMSE: 0.7944
Pre-Training Epoch 24/30, Train RMSE: 0.8037
Pre-Training Epoch 25/30, Train RMSE: 0.8380
Pre-Training Epoch 26/30, Train RMSE: 0.8651
Pre-Training Epoch 27/30, Train RMSE: 0.8807
Pre-Training Epoch 28/30, Train RMSE: 0.8691
Pre-Training Epoch 29/30, Train RMSE: 0.8409
Pre-Training Epoch 30/30, Train RMSE: 0.8123
Fine-Tuning Epoch 1/100, Train RMSE: 0.8021
Fine-Tuning Epoch 2/100, Train RMSE: 0.8015
Fine-Tuning Epoch 3/100, Train RMSE: 0.7963
Fine-Tuning Epoch 4/100, Train RMSE: 0.7951
Fine-Tuning Epoch 5/100, Train RMSE: 0.7947
Fine-Tuning Epoch 6/100, Train RMSE: 0.7890
Fine-Tuning Epoch 7/100, Train RMSE: 0.7833
Fine-Tuning Epoch 8/100, Train RMSE: 0.7787
Fine-Tuning Epoch 9/100, Train RMSE: 0.7752
Fine-Tuning Epoch 10/100, Train RMSE: 0.7720
Fine-Tuning Epoch 11/100, Train RMSE: 0.7703
Fine-Tuning Epoch 12/100, Train RMSE: 0.7707
Fine-Tuning Epoch 13/100, Train RMSE: 0.7725
Fine-Tuning Epoch 14/100, Train RMSE: 0.7736
Fine-Tuning Epoch 15/100, Train RMSE: 0.7765
Fine-Tuning Epoch 16/100, Train RMSE: 0.7798
Fine-Tuning Epoch 17/100, Train RMSE: 0.7835
Fine-Tuning Epoch 18/100, Train RMSE: 0.7873
Fine-Tuning Epoch 19/100, Train RMSE: 0.7886
Fine-Tuning Epoch 20/100, Train RMSE: 0.7889
Fine-Tuning Epoch 21/100, Train RMSE: 0.7888
Fine-Tuning Epoch 22/100, Train RMSE: 0.7871
Fine-Tuning Epoch 23/100, Train RMSE: 0.7828
Fine-Tuning Epoch 24/100, Train RMSE: 0.7783
Fine-Tuning Epoch 25/100, Train RMSE: 0.7742
Fine-Tuning Epoch 26/100, Train RMSE: 0.7700
Fine-Tuning Epoch 27/100, Train RMSE: 0.7665
Fine-Tuning Epoch 28/100, Train RMSE: 0.7642
Fine-Tuning Epoch 29/100, Train RMSE: 0.7627
Fine-Tuning Epoch 30/100, Train RMSE: 0.7618
Fine-Tuning Epoch 31/100, Train RMSE: 0.7609
Fine-Tuning Epoch 32/100, Train RMSE: 0.7612
Fine-Tuning Epoch 33/100, Train RMSE: 0.7625
Fine-Tuning Epoch 34/100, Train RMSE: 0.7647
Fine-Tuning Epoch 35/100, Train RMSE: 0.7672
Fine-Tuning Epoch 36/100, Train RMSE: 0.7707
Fine-Tuning Epoch 37/100, Train RMSE: 0.7753
Fine-Tuning Epoch 38/100, Train RMSE: 0.7801
Fine-Tuning Epoch 39/100, Train RMSE: 0.7826
Fine-Tuning Epoch 40/100, Train RMSE: 0.7856
Early stopping fine-tuning at epoch: 41
helllooooooooooooow

TEST:
...
                  |    MAE |   RMSE | Train (s) | Test (s)
----------------- + ------ + ------ + --------- + --------
GlobalLocalKernel | 1.0615 | 1.0671 |    2.9344 |   0.0836


========================================
