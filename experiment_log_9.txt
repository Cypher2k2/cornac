
========================================
Experiment conducted on: 2024-12-14 14:56:31.285239

Hyperparameters:
name: GlobalLocalKernel
trainable: True
verbose: True
is_fitted: False
ignored_attrs: ['train_set', 'val_set', 'test_set']
num_users: None
num_items: None
uid_map: None
iid_map: None
max_rating: 5.0
min_rating: 1.0
global_mean: None
_Recommender__user_ids: None
_Recommender__item_ids: None
n_hid: 10
n_dim: 2
n_layers: 2
lambda_s: 0.006
lambda_2: 0.001
gk_size: 3
dot_scale: 1
max_epoch_p: 11
max_epoch_f: 10
tol_p: 0.0001
tol_f: 1e-05
patience_p: 10
patience_f: 10
lr_p: 0.1
lr_f: 0.1
device: cpu
model: CompleteNet(
  (local_kernel_net): KernelNet(
    (layers): ModuleList(
      (0-1): 2 x KernelLayer(
        (activation): Sigmoid()
      )
      (2): KernelLayer(
        (activation): Identity()
      )
    )
    (dropout): Dropout(p=0.33, inplace=False)
  )
)
train_r_local: [[1.7862409 3.7904427 2.2713401 ... 3.9308016 4.1415873 2.3545623]
 [1.8098971 3.8735347 2.3031673 ... 3.9851453 4.2259607 2.4135017]
 [1.8194615 3.9009283 2.3160815 ... 4.028461  4.2595353 2.4159725]
 ...
 [1.7831967 3.7818234 2.2670496 ... 3.9160302 4.1308055 2.3544216]
 [1.7924736 3.8139198 2.2797391 ... 3.9409547 4.1644974 2.374955 ]
 [1.7831967 3.7818234 2.2670496 ... 3.9160302 4.1308055 2.3544216]]
_train_r: [[3. 0. 0. ... 0. 0. 0.]
 [0. 4. 0. ... 0. 0. 0.]
 [0. 4. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
_train_mask: [[1. 0. 0. ... 0. 0. 0.]
 [0. 1. 0. ... 0. 0. 0.]
 [0. 1. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]

Test Results:
hi
Pre-Training Epoch 1/11, Train RMSE: 2.7954
hi
Pre-Training Epoch 2/11, Train RMSE: 2.7954
hi
Pre-Training Epoch 3/11, Train RMSE: 2.7623
hi
Pre-Training Epoch 4/11, Train RMSE: 2.3646
hi
Pre-Training Epoch 5/11, Train RMSE: 1.8258
hi
Pre-Training Epoch 6/11, Train RMSE: 1.3236
hi
Pre-Training Epoch 7/11, Train RMSE: 1.0857
hi
Pre-Training Epoch 8/11, Train RMSE: 1.1549
hi
Pre-Training Epoch 9/11, Train RMSE: 1.1521
hi
Pre-Training Epoch 10/11, Train RMSE: 1.0596
hi
Pre-Training Epoch 11/11, Train RMSE: 1.1653
Fine-Tuning Epoch 1/10, Train RMSE: 1.2124
Fine-Tuning Epoch 2/10, Train RMSE: 1.1338
Fine-Tuning Epoch 3/10, Train RMSE: 1.2263
Fine-Tuning Epoch 4/10, Train RMSE: 1.1828
Fine-Tuning Epoch 5/10, Train RMSE: 1.0981
Fine-Tuning Epoch 6/10, Train RMSE: 1.0623
Fine-Tuning Epoch 7/10, Train RMSE: 1.0499
Fine-Tuning Epoch 8/10, Train RMSE: 1.0291
Fine-Tuning Epoch 9/10, Train RMSE: 1.0305
Fine-Tuning Epoch 10/10, Train RMSE: 1.0553
helllooooooooooooow

TEST:
...
                  |    MAE |   RMSE | Train (s) | Test (s)
----------------- + ------ + ------ + --------- + --------
GlobalLocalKernel | 0.9324 | 1.0286 |    2.0803 |   9.6522


========================================
