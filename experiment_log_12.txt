
========================================
Experiment conducted on: 2024-12-14 15:03:35.945173

Hyperparameters:
name: GlobalLocalKernel
trainable: True
verbose: True
is_fitted: False
ignored_attrs: ['train_set', 'val_set', 'test_set']
num_users: None
num_items: None
uid_map: None
iid_map: None
max_rating: 4.0
min_rating: 1.0
global_mean: None
_Recommender__user_ids: None
_Recommender__item_ids: None
n_hid: 10
n_dim: 2
n_layers: 2
lambda_s: 0.006
lambda_2: 0.001
gk_size: 3
dot_scale: 1
max_epoch_p: 11
max_epoch_f: 10
tol_p: 0.0001
tol_f: 1e-05
patience_p: 10
patience_f: 10
lr_p: 0.1
lr_f: 0.1
device: cpu
model: CompleteNet(
  (local_kernel_net): KernelNet(
    (layers): ModuleList(
      (0-1): 2 x KernelLayer(
        (activation): Sigmoid()
      )
      (2): KernelLayer(
        (activation): Identity()
      )
    )
    (dropout): Dropout(p=0.33, inplace=False)
  )
)
train_r_local: [[2.4343624 3.8545873 2.7392533 ... 3.457223  3.9285028 1.9940946]
 [2.4660501 3.8995204 2.7729685 ... 3.4968312 3.9814517 2.0049841]
 [2.4496148 3.870842  2.7558439 ... 3.4721377 3.9461834 1.9956937]
 ...
 [2.4251416 3.8361835 2.7235134 ... 3.446127  3.9152336 1.9902709]
 [2.4251416 3.8361835 2.7235134 ... 3.446127  3.9152336 1.9902709]
 [2.4389083 3.8435922 2.739875  ... 3.4509299 3.9247258 1.9837745]]
_train_r: [[3. 0. 0. ... 0. 0. 0.]
 [0. 4. 0. ... 0. 0. 0.]
 [0. 4. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
_train_mask: [[1. 0. 0. ... 0. 0. 0.]
 [0. 1. 0. ... 0. 0. 0.]
 [0. 1. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]

Test Results:
Pre-Training Epoch 1/11, Train RMSE: 2.7954
Pre-Training Epoch 2/11, Train RMSE: 2.7954
Pre-Training Epoch 3/11, Train RMSE: 2.7857
Pre-Training Epoch 4/11, Train RMSE: 2.4588
Pre-Training Epoch 5/11, Train RMSE: 1.9610
Pre-Training Epoch 6/11, Train RMSE: 1.4614
Pre-Training Epoch 7/11, Train RMSE: 1.1359
Pre-Training Epoch 8/11, Train RMSE: 1.1327
Pre-Training Epoch 9/11, Train RMSE: 1.1802
Pre-Training Epoch 10/11, Train RMSE: 1.0934
Pre-Training Epoch 11/11, Train RMSE: 1.0821
Pre-Training Epoch 1/11, Train RMSE: 1.2752
Fine-Tuning Epoch 1/10, Train RMSE: 1.2752
Pre-Training Epoch 2/11, Train RMSE: 1.1445
Fine-Tuning Epoch 2/10, Train RMSE: 1.1445
Pre-Training Epoch 3/11, Train RMSE: 1.0750
Fine-Tuning Epoch 3/10, Train RMSE: 1.0750
Pre-Training Epoch 4/11, Train RMSE: 1.0659
Fine-Tuning Epoch 4/10, Train RMSE: 1.0659
Pre-Training Epoch 5/11, Train RMSE: 1.1005
Fine-Tuning Epoch 5/10, Train RMSE: 1.1005
Pre-Training Epoch 6/11, Train RMSE: 1.0901
Fine-Tuning Epoch 6/10, Train RMSE: 1.0901
Pre-Training Epoch 7/11, Train RMSE: 1.0659
Fine-Tuning Epoch 7/10, Train RMSE: 1.0659
Pre-Training Epoch 8/11, Train RMSE: 1.0470
Fine-Tuning Epoch 8/10, Train RMSE: 1.0470
Pre-Training Epoch 9/11, Train RMSE: 1.0353
Fine-Tuning Epoch 9/10, Train RMSE: 1.0353
Pre-Training Epoch 10/11, Train RMSE: 1.0350
Fine-Tuning Epoch 10/10, Train RMSE: 1.0350
helllooooooooooooow

TEST:
...
                  |    MAE |   RMSE | Train (s) | Test (s)
----------------- + ------ + ------ + --------- + --------
GlobalLocalKernel | 0.8653 | 0.9704 |    1.9956 |   8.5123


========================================
